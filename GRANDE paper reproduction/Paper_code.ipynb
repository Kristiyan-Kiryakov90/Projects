{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "acccd7d4-8880-4798-b0a2-df71271c199b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "#!pip install GRANDE\n",
    "#!pip install xgboost catboost scikit-learn openml matplotlib seaborn\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e38c7e3-ce72-4c8f-878a-8bc2568da047",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# GPU Configuration\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '0'\n",
    "os.environ['TF_FORCE_GPU_ALLOW_GROWTH'] = 'true'\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.metrics import accuracy_score, f1_score, roc_auc_score, confusion_matrix\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import openml\n",
    "\n",
    "\n",
    "from GRANDE import GRANDE\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d7eed6-4794-4adf-9c72-544a80eff6ab",
   "metadata": {},
   "source": [
    "### Understanding GRANDE\n",
    "\n",
    "GRANDE extends gradient-based decision trees to ensembles. The key innovation is **instance-wise weighting**, where each tree's contribution depends on which leaf node the sample falls into.\n",
    "\n",
    "The ensemble prediction is computed as:\n",
    "\n",
    "$$G(x|W, \\mathcal{L}, T, I) = \\sigma(w(x|W, \\mathcal{L}, T, I)) \\cdot p(x|\\mathcal{L}, T, I)$$\n",
    "\n",
    "where:\n",
    "- $\\sigma$ is the softmax function\n",
    "- $w(x|W, \\mathcal{L}, T, I)$ computes instance-wise weights for each tree\n",
    "- $p(x|\\mathcal{L}, T, I)$ are the individual tree predictions\n",
    "\n",
    "This allows GRANDE to learn both simple rules (for easy instances) and complex patterns (for difficult instances) within a single model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f5d55919-4f2b-4e99-ad40-c3b80724fd88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "# Optimized parameter using Optuna with 250 trials from the paper\n",
    "\n",
    "def get_optimized_params_grande(dataset_name):\n",
    "    \"\"\"\n",
    "    Returns optimized GRANDE hyperparameters from Table 25 of the paper.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    dataset_name : str\n",
    "        Name of the dataset ('wdbc', 'churn', or 'phishing')\n",
    "    \"\"\"\n",
    "    \n",
    "    params_dict = {\n",
    "        'wdbc': {\n",
    "            'depth': 4,\n",
    "            'n_estimators': 1024,\n",
    "            'learning_rate_weights': 0.0151,\n",
    "            'learning_rate_index': 0.0140,\n",
    "            'learning_rate_values': 0.1127,\n",
    "            'learning_rate_leaf': 0.1758,\n",
    "            'optimizer': 'adam',\n",
    "            'cosine_decay_steps': 0,\n",
    "            'focal_loss': False,\n",
    "            'temperature': 0.0,\n",
    "            'from_logits': True,\n",
    "            'use_class_weights': True,\n",
    "            'dropout': 0.5,\n",
    "            'selected_variables': 0.8941,\n",
    "            'data_subset_fraction': 0.8480,\n",
    "        },\n",
    "        'churn': {\n",
    "            'depth': 6,\n",
    "            'n_estimators': 2048,\n",
    "            'learning_rate_weights': 0.0293,\n",
    "            'learning_rate_index': 0.0716,\n",
    "            'learning_rate_values': 0.0179,\n",
    "            'learning_rate_leaf': 0.0225,\n",
    "            'optimizer': 'adam',\n",
    "            'cosine_decay_steps': 1000,\n",
    "            'focal_loss': False,\n",
    "            'temperature': 0.0,\n",
    "            'from_logits': True,\n",
    "            'use_class_weights': True,\n",
    "            'dropout': 0.0,\n",
    "            'selected_variables': 0.6920,\n",
    "            'data_subset_fraction': 0.8174,\n",
    "        },\n",
    "        'phishing': {\n",
    "            'depth': 6,\n",
    "            'n_estimators': 2048,\n",
    "            'learning_rate_weights': 0.0040,\n",
    "            'learning_rate_index': 0.0118,\n",
    "            'learning_rate_values': 0.0104,\n",
    "            'learning_rate_leaf': 0.1850,\n",
    "            'optimizer': 'adam',\n",
    "            'cosine_decay_steps': 0.1,\n",
    "            'focal_loss': False,\n",
    "            'temperature': 0.0,\n",
    "            'from_logits': True,\n",
    "            'use_class_weights': True,\n",
    "            'dropout': 0.0,\n",
    "            'selected_variables': 0.9792,\n",
    "            'data_subset_fraction': 0.9588,\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return params_dict[dataset_name]\n",
    "\n",
    "\n",
    "def get_optimized_params_xgboost(dataset_name):\n",
    "    \"\"\"\n",
    "    Returns optimized XGBoost hyperparameters from Table 27 of the paper.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    dataset_name : str\n",
    "        Name of the dataset ('wdbc', 'churn', or 'phishing')\n",
    "    \"\"\"\n",
    "    \n",
    "    params_dict = {\n",
    "        'wdbc': {\n",
    "            'learning_rate': 0.2640,\n",
    "            'max_depth': 2,\n",
    "            'reg_alpha': 0.0007,\n",
    "            'reg_lambda': 0.0000,\n",
    "        },\n",
    "        'churn': {\n",
    "            'learning_rate': 0.0473,\n",
    "            'max_depth': 6,\n",
    "            'reg_alpha': 0.0000,\n",
    "            'reg_lambda': 0.3132,\n",
    "        },\n",
    "        'phishing': {\n",
    "            'learning_rate': 0.1243,\n",
    "            'max_depth': 11,\n",
    "            'reg_alpha': 0.0017,\n",
    "            'reg_lambda': 0.3710,\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return params_dict[dataset_name]\n",
    "\n",
    "\n",
    "def get_optimized_params_catboost(dataset_name):\n",
    "    \"\"\"\n",
    "    Returns optimized CatBoost hyperparameters from Table 28 of the paper.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    dataset_name : str\n",
    "        Name of the dataset ('wdbc', 'churn', or 'phishing')\n",
    "    \"\"\"\n",
    "    \n",
    "    params_dict = {\n",
    "        'wdbc': {\n",
    "            'learning_rate': 0.1339,\n",
    "            'depth': 3,\n",
    "            'l2_leaf_reg': 0.7173,\n",
    "        },\n",
    "        'churn': {\n",
    "            'learning_rate': 0.0248,\n",
    "            'depth': 9,\n",
    "            'l2_leaf_reg': 7.0362,\n",
    "        },\n",
    "        'phishing': {\n",
    "            'learning_rate': 0.0239,\n",
    "            'depth': 8,\n",
    "            'l2_leaf_reg': 1.6860,\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    return params_dict[dataset_name]\n",
    "\n",
    "\n",
    "print(\"OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0aeadba5-9ec4-49ba-84a1-fd4b4831c4ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading dataset\n",
    "def load_dataset(dataset_id, dataset_name, split_data=True):\n",
    "\n",
    "    print(f\"Loading dataset: {dataset_name} (ID: {dataset_id})\")\n",
    "    \n",
    "    # Load dataset from OpenML\n",
    "    dataset = openml.datasets.get_dataset(dataset_id)\n",
    "    X, y, categorical_indicator, attribute_names = dataset.get_data(\n",
    "        target=dataset.default_target_attribute\n",
    "    )\n",
    "    \n",
    "    # Get categorical feature indices\n",
    "    categorical_feature_indices = [\n",
    "        idx for idx, is_cat in enumerate(categorical_indicator) if is_cat\n",
    "    ]\n",
    "    \n",
    "    # Encode labels to numeric if they are strings\n",
    "    label_encoder = LabelEncoder()\n",
    "    y_encoded = label_encoder.fit_transform(y)\n",
    "    \n",
    "    print(f\"  - Original labels: {label_encoder.classes_}\")\n",
    "    print(f\"  - Encoded to: {np.unique(y_encoded)}\")\n",
    "    print(f\"  - Total samples: {len(X)}\")\n",
    "    print(f\"  - Features: {X.shape[1]}\")\n",
    "    print(f\"  - Categorical features: {len(categorical_feature_indices)}\")\n",
    "    \n",
    "    if not split_data:\n",
    "        # Return full dataset for CV\n",
    "        return {\n",
    "            'X': X,\n",
    "            'y': y_encoded,\n",
    "            'cat_idx': categorical_feature_indices,\n",
    "            'feature_names': attribute_names,\n",
    "            'label_encoder': label_encoder\n",
    "        }\n",
    "    \n",
    "    # Original splitting logic\n",
    "    X_temp, X_test, y_temp, y_test = train_test_split(\n",
    "        X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded\n",
    "    )\n",
    "    X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "        X_temp, y_temp, test_size=0.25, random_state=42, stratify=y_temp\n",
    "    )\n",
    "    \n",
    "    print(f\"  - Train samples: {len(X_train)}\")\n",
    "    print(f\"  - Validation samples: {len(X_valid)}\")\n",
    "    print(f\"  - Test samples: {len(X_test)}\")\n",
    "    \n",
    "    return {\n",
    "        'name': dataset_name,\n",
    "        'X_train': X_train,\n",
    "        'X_valid': X_valid,\n",
    "        'X_test': X_test,\n",
    "        'y_train': y_train,\n",
    "        'y_valid': y_valid,\n",
    "        'y_test': y_test,\n",
    "        'cat_idx': categorical_feature_indices,\n",
    "        'feature_names': attribute_names,\n",
    "        'label_encoder': label_encoder\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5a232bf-7693-47dc-9163-d0121d9f0e7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Training functions\n",
    "\n",
    "def train_grande(data, dataset_name):\n",
    "\n",
    "    \n",
    "    # Load optimized parameters for this dataset\n",
    "    params = get_optimized_params_grande(dataset_name)\n",
    "    \n",
    "    args = {\n",
    "        'epochs': 1000,\n",
    "        'early_stopping_epochs': 25,\n",
    "        'batch_size': 64,\n",
    "        'cat_idx': data['cat_idx'],\n",
    "        'objective': 'binary',\n",
    "        'random_seed': 42,\n",
    "        'verbose': 0,\n",
    "    }\n",
    "    \n",
    "\n",
    "    \n",
    "    # Ensure labels are integers\n",
    "    y_train = np.array(data['y_train']).astype(int)\n",
    "    y_valid = np.array(data['y_valid']).astype(int)\n",
    "    y_test = np.array(data['y_test']).astype(int)\n",
    "    \n",
    "    model = GRANDE(params=params, args=args)\n",
    "    model.fit(\n",
    "        X_train=data['X_train'],\n",
    "        y_train=y_train,\n",
    "        X_val=data['X_valid'],\n",
    "        y_val=y_valid\n",
    "    )\n",
    "    \n",
    "    preds = model.predict(data['X_test'])\n",
    "    \n",
    "    #  Metrics\n",
    "    y_pred = np.round(preds[:, 1]).astype(int)\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    roc_auc = roc_auc_score(y_test, preds[:, 1])\n",
    "    \n",
    "\n",
    "    \n",
    "    return model, {\n",
    "        'accuracy': accuracy,\n",
    "        'f1_score': f1,\n",
    "        'roc_auc': roc_auc,\n",
    "        'predictions': preds\n",
    "    }\n",
    "\n",
    "\n",
    "def train_xgboost(data, dataset_name):\n",
    "\n",
    "    \n",
    "    \n",
    "    # Load optimized parameters for this dataset\n",
    "    opt_params = get_optimized_params_xgboost(dataset_name)\n",
    "    \n",
    "    xgb_params = {\n",
    "        'n_estimators': 1000,\n",
    "        'learning_rate': opt_params['learning_rate'],\n",
    "        'max_depth': opt_params['max_depth'],\n",
    "        'reg_alpha': opt_params['reg_alpha'],\n",
    "        'reg_lambda': opt_params['reg_lambda'],\n",
    "        'random_state': 42,\n",
    "        'eval_metric': 'logloss',\n",
    "        'early_stopping_rounds': 25\n",
    "    }\n",
    "    \n",
    "    # Convert categorical features\n",
    "    X_train_enc = data['X_train'].copy()\n",
    "    X_test_enc = data['X_test'].copy()\n",
    "    \n",
    "    for idx in data['cat_idx']:\n",
    "        le = LabelEncoder()\n",
    "        train_col = X_train_enc.iloc[:, idx]\n",
    "        test_col = X_test_enc.iloc[:, idx]\n",
    "        \n",
    "        if hasattr(train_col, 'cat'):\n",
    "            train_values = train_col.astype(str)\n",
    "            test_values = test_col.astype(str)\n",
    "        else:\n",
    "            train_values = train_col.fillna('missing').astype(str)\n",
    "            test_values = test_col.fillna('missing').astype(str)\n",
    "        \n",
    "        X_train_enc.iloc[:, idx] = le.fit_transform(train_values)\n",
    "        \n",
    "        test_encoded = []\n",
    "        for val in test_values:\n",
    "            if val in le.classes_:\n",
    "                test_encoded.append(le.transform([val])[0])\n",
    "            else:\n",
    "                test_encoded.append(-1)\n",
    "        X_test_enc.iloc[:, idx] = test_encoded\n",
    "    \n",
    "    model = xgb.XGBClassifier(**xgb_params)\n",
    "    \n",
    "    model.fit(\n",
    "        X_train_enc, data['y_train'],\n",
    "        eval_set=[(X_test_enc, data['y_test'])],\n",
    "        verbose=False\n",
    "    )\n",
    "    \n",
    "    preds_proba = model.predict_proba(X_test_enc)\n",
    "    y_pred = model.predict(X_test_enc)\n",
    "    \n",
    "    y_test = np.array(data['y_test']).astype(int)\n",
    "    y_pred = np.array(y_pred).astype(int)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    roc_auc = roc_auc_score(y_test, preds_proba[:, 1])\n",
    "    \n",
    "    return model, {\n",
    "        'accuracy': accuracy,\n",
    "        'f1_score': f1,\n",
    "        'roc_auc': roc_auc,\n",
    "        'predictions': preds_proba\n",
    "    }\n",
    "\n",
    "\n",
    "def train_catboost(data, dataset_name):\n",
    "\n",
    "    \n",
    "    # Load optimized parameters for this dataset\n",
    "    opt_params = get_optimized_params_catboost(dataset_name)\n",
    "    \n",
    "    cat_params = {\n",
    "        'iterations': 1000,\n",
    "        'learning_rate': opt_params['learning_rate'],\n",
    "        'depth': opt_params['depth'],\n",
    "        'l2_leaf_reg': opt_params['l2_leaf_reg'],\n",
    "        'random_state': 42,\n",
    "        'verbose': False,\n",
    "        'early_stopping_rounds': 25,\n",
    "        'cat_features': data['cat_idx'] if len(data['cat_idx']) > 0 else None\n",
    "    }\n",
    "    \n",
    "    y_train = np.array(data['y_train']).astype(int)\n",
    "    y_test = np.array(data['y_test']).astype(int)\n",
    "    \n",
    "    model = CatBoostClassifier(**cat_params)\n",
    "    \n",
    "    model.fit(\n",
    "        data['X_train'], y_train,\n",
    "        eval_set=(data['X_test'], y_test)\n",
    "    )\n",
    "    \n",
    "    preds_proba = model.predict_proba(data['X_test'])\n",
    "    y_pred = model.predict(data['X_test']).astype(int)\n",
    "    \n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='macro')\n",
    "    roc_auc = roc_auc_score(y_test, preds_proba[:, 1])\n",
    "    \n",
    "\n",
    "    return model, {\n",
    "        'accuracy': accuracy,\n",
    "        'f1_score': f1,\n",
    "        'roc_auc': roc_auc,\n",
    "        'predictions': preds_proba\n",
    "    }\n",
    "\n",
    "\n",
    "\n",
    "print(\"OK\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b7066294-e37e-47bc-8789-80c450133de0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "OK\n"
     ]
    }
   ],
   "source": [
    "# Cross validation\n",
    "\n",
    "def evaluate_cv_5fold(dataset_id, dataset_name, dataset_key):\n",
    "\n",
    "    from sklearn.model_selection import StratifiedKFold\n",
    "    \n",
    "    # Load full dataset without splitting\n",
    "    full_data = load_dataset(dataset_id, dataset_name, split_data=False)\n",
    "    \n",
    "    X = full_data['X']\n",
    "    y = full_data['y']\n",
    "    cat_idx = full_data['cat_idx']\n",
    "    \n",
    "    # Storage for results\n",
    "    results = {\n",
    "        'GRANDE': {'f1': [], 'accuracy': [], 'roc_auc': []},\n",
    "        'XGBoost': {'f1': [], 'accuracy': [], 'roc_auc': []},\n",
    "        'CatBoost': {'f1': [], 'accuracy': [], 'roc_auc': []}\n",
    "    }\n",
    "    \n",
    "    # 5-fold CV\n",
    "    skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "    \n",
    "    print(f\"\\nStarting 5-fold cross-validation...\")\n",
    "    \n",
    "    for fold, (train_val_idx, test_idx) in enumerate(skf.split(X, y), 1):\n",
    "        print(f\"\\nFold {fold}/5\") \n",
    "        \n",
    "        # Split data\n",
    "        X_train_val = X.iloc[train_val_idx]\n",
    "        X_test = X.iloc[test_idx]\n",
    "        y_train_val = y[train_val_idx]\n",
    "        y_test = y[test_idx]\n",
    "        \n",
    "        # Split train_val into train and validation\n",
    "        X_train, X_valid, y_train, y_valid = train_test_split(\n",
    "            X_train_val, y_train_val, test_size=0.2, random_state=42, stratify=y_train_val\n",
    "        )\n",
    "        \n",
    "        # Create fold data dictionary\n",
    "        fold_data = {\n",
    "            'X_train': X_train,\n",
    "            'X_valid': X_valid,\n",
    "            'X_test': X_test,\n",
    "            'y_train': y_train,\n",
    "            'y_valid': y_valid,\n",
    "            'y_test': y_test,\n",
    "            'cat_idx': cat_idx\n",
    "        }\n",
    "        \n",
    "        # Train models\n",
    "        _, grande_res = train_grande(fold_data, dataset_key)\n",
    "        results['GRANDE']['f1'].append(grande_res['f1_score'])\n",
    "        results['GRANDE']['accuracy'].append(grande_res['accuracy'])\n",
    "        results['GRANDE']['roc_auc'].append(grande_res['roc_auc'])\n",
    "        \n",
    "        _, xgb_res = train_xgboost(fold_data, dataset_key)\n",
    "        results['XGBoost']['f1'].append(xgb_res['f1_score'])\n",
    "        results['XGBoost']['accuracy'].append(xgb_res['accuracy'])\n",
    "        results['XGBoost']['roc_auc'].append(xgb_res['roc_auc'])\n",
    "        \n",
    "        _, cat_res = train_catboost(fold_data, dataset_key)\n",
    "        results['CatBoost']['f1'].append(cat_res['f1_score'])\n",
    "        results['CatBoost']['accuracy'].append(cat_res['accuracy'])\n",
    "        results['CatBoost']['roc_auc'].append(cat_res['roc_auc'])\n",
    "    \n",
    "    # Create results DataFrame\n",
    "    results_list = []\n",
    "    for model in ['GRANDE', 'XGBoost', 'CatBoost']:\n",
    "        results_list.append({\n",
    "            'Model': model,\n",
    "            'F1-Score': f\"{np.mean(results[model]['f1']):.4f} ± {np.std(results[model]['f1']):.4f}\",\n",
    "            'Accuracy': f\"{np.mean(results[model]['accuracy']):.4f} ± {np.std(results[model]['accuracy']):.4f}\",\n",
    "            'ROC-AUC': f\"{np.mean(results[model]['roc_auc']):.4f} ± {np.std(results[model]['roc_auc']):.4f}\"\n",
    "        })\n",
    "    \n",
    "    return pd.DataFrame(results_list), results\n",
    "\n",
    "print(\"OK\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d133e6c2-fb04-4816-95ae-0354639a9f58",
   "metadata": {},
   "source": [
    "\n",
    "### Experiment 1: Small Dataset - WDBC (Breast Cancer)\n",
    "\n",
    "Starting with the Wisconsin Diagnostic Breast Cancer (WDBC) dataset, which is a small dataset with 569 samples and 30 numerical features. This demonstrates GRANDE's performance on datasets with limited training data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eaf5a83e-94f6-4c33-b2b5-e722663b5d82",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset: WDBC (ID: 1510)\n",
      "  - Original labels: ['1' '2']\n",
      "  - Encoded to: [0 1]\n",
      "  - Total samples: 569\n",
      "  - Features: 30\n",
      "  - Categorical features: 0\n",
      "\n",
      "Starting 5-fold cross-validation...\n",
      "\n",
      "Fold 1/5\n",
      "\n",
      "Fold 2/5\n",
      "\n",
      "Fold 3/5\n",
      "WARNING:tensorflow:5 out of the last 5 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000017E6EDC44A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "WARNING:tensorflow:6 out of the last 6 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000017E6EDC44A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "\n",
      "Fold 4/5\n",
      "\n",
      "Fold 5/5\n",
      "WDBC RESULTS (5-Fold CV)\n",
      "   Model        F1-Score        Accuracy         ROC-AUC\n",
      "  GRANDE 0.9643 ± 0.0091 0.9666 ± 0.0085 0.9930 ± 0.0074\n",
      " XGBoost 0.9601 ± 0.0213 0.9631 ± 0.0195 0.9909 ± 0.0064\n",
      "CatBoost 0.9605 ± 0.0197 0.9631 ± 0.0187 0.9948 ± 0.0047\n",
      "\n",
      "Paper: GRANDE 0.975±0.010, XGBoost 0.953±0.030, CatBoost 0.963±0.023\n"
     ]
    }
   ],
   "source": [
    "\n",
    "results_wdbc, details_wdbc = evaluate_cv_5fold(1510, \"WDBC\", 'wdbc')\n",
    "\n",
    "print(\"WDBC RESULTS (5-Fold CV)\")\n",
    "print(results_wdbc.to_string(index=False))\n",
    "print(\"\\nPaper: GRANDE 0.975±0.010, XGBoost 0.953±0.030, CatBoost 0.963±0.023\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b5ad4f7-379e-4a8a-b225-266e6d71c4a3",
   "metadata": {},
   "source": [
    "### Experiment 2: Medium Dataset - Churn Prediction\n",
    "\n",
    "Testing on the Churn dataset (5,000 samples, 20 features) which includes both numerical and categorical features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "270ecf2b-6627-46d1-a6ac-8aec035603a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset: Churn (ID: 40701)\n",
      "  - Original labels: ['0' '1']\n",
      "  - Encoded to: [0 1]\n",
      "  - Total samples: 5000\n",
      "  - Features: 20\n",
      "  - Categorical features: 4\n",
      "\n",
      "Starting 5-fold cross-validation...\n",
      "\n",
      "Fold 1/5\n",
      "\n",
      "Fold 2/5\n",
      "\n",
      "Fold 3/5\n",
      "\n",
      "Fold 4/5\n",
      "\n",
      "Fold 5/5\n",
      "CHURN RESULTS (5-Fold CV)\n",
      "   Model        F1-Score        Accuracy         ROC-AUC\n",
      "  GRANDE 0.9063 ± 0.0041 0.9576 ± 0.0022 0.9213 ± 0.0174\n",
      " XGBoost 0.9095 ± 0.0098 0.9594 ± 0.0038 0.9219 ± 0.0177\n",
      "CatBoost 0.9100 ± 0.0096 0.9598 ± 0.0037 0.9264 ± 0.0164\n",
      "\n",
      "Paper: GRANDE 0.914±0.017, XGBoost 0.900±0.017, CatBoost 0.869±0.021\n"
     ]
    }
   ],
   "source": [
    "\n",
    "results_churn, details_churn = evaluate_cv_5fold(40701, \"Churn\", 'churn')\n",
    "print(\"CHURN RESULTS (5-Fold CV)\")\n",
    "print(results_churn.to_string(index=False))\n",
    "print(\"\\nPaper: GRANDE 0.914±0.017, XGBoost 0.900±0.017, CatBoost 0.869±0.021\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "799b0e21-021b-4b42-9da9-20c262a4ba27",
   "metadata": {},
   "source": [
    "\n",
    "### Experiment 3: Understanding Instance-Wise Weighting\n",
    "\n",
    "The PhishingWebsites dataset is perfect for demonstrating GRANDE's instance-wise weighting capability. Some phishing websites can be identified using simple rules (e.g., \"has prefix/suffix in domain\"), while others require complex patterns.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fb390581-bec1-467a-b838-7c1a8ba904b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset: PhishingWebsites (ID: 4534)\n",
      "  - Original labels: ['-1' '1']\n",
      "  - Encoded to: [0 1]\n",
      "  - Total samples: 11055\n",
      "  - Features: 30\n",
      "  - Categorical features: 30\n",
      "\n",
      "Starting 5-fold cross-validation...\n",
      "\n",
      "Fold 1/5\n",
      "\n",
      "Fold 2/5\n",
      "\n",
      "Fold 3/5\n",
      "\n",
      "Fold 4/5\n",
      "\n",
      "Fold 5/5\n",
      "PHISHINGWEBSITES RESULTS (5-Fold CV)\n",
      "   Model        F1-Score        Accuracy         ROC-AUC\n",
      "  GRANDE 0.9680 ± 0.0028 0.9684 ± 0.0028 0.9958 ± 0.0007\n",
      " XGBoost 0.9677 ± 0.0022 0.9682 ± 0.0022 0.9959 ± 0.0005\n",
      "CatBoost 0.9652 ± 0.0016 0.9657 ± 0.0015 0.9955 ± 0.0006\n",
      "\n",
      "Paper: GRANDE 0.969±0.006, XGBoost 0.968±0.006, CatBoost 0.965±0.003\n"
     ]
    }
   ],
   "source": [
    "\n",
    "results_phishing, details_phishing = evaluate_cv_5fold(4534, \"PhishingWebsites\", 'phishing')\n",
    "print(\"PHISHINGWEBSITES RESULTS (5-Fold CV)\")\n",
    "print(results_phishing.to_string(index=False))\n",
    "print(\"\\nPaper: GRANDE 0.969±0.006, XGBoost 0.968±0.006, CatBoost 0.965±0.003\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f6bad81-5a97-499d-aa10-984675f02ee9",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### REPRODUCTION \n",
    "**Experimental Reproduction Methodology**\n",
    "\n",
    "This notebook reproduces the key experiments from \"GRANDE: Gradient-Based Decision Tree Ensembles for Tabular Data\" (Marton et al., ICLR 2024). The reproduction focused on three representative datasets from the paper's benchmark suite: WDBC (569 samples, 30 features), Churn (5,000 samples, 20 features with 4 categorical), and PhishingWebsites (11,055 samples, 30 categorical features).\n",
    "\n",
    "**Reproduction Approach**\n",
    "The experiments were conducted using the following methodology aligned with the paper's evaluation protocol:\n",
    "- Model Implementation: GRANDE v0.1.6 from PyPI, XGBoost 3.0.5, CatBoost 1.2.8.\n",
    "- Optimized Hyperparameters extracted directly from the paper's appendix (Tables 25, 27, 28).\n",
    "- Stratified 5-fold cross-validation matching the paper's methodology, with each fold using an 80/20 train-validation split for early stopping.\n",
    "- Computational Environment: Python 3.11, TensorFlow 2.16.1, scikit-learn 1.3.2.\n",
    "- Datasets loaded directly from OpenML using the same dataset IDs as specified in the paper.\n",
    "- Relied on GRANDE's built-in preprocessing pipeline, which handles categorical encoding and feature transformation automatically.\n",
    "  \n",
    "**Experimental Conditions and Limitations**\n",
    "- The paper's experiments were likely conducted in 2023 with earlier library versions. This reproduction uses current releases (2024-2025), which may have different optimization behaviors, numerical precision, or default parameter handling.\n",
    "- While the paper specifies leave-one-out encoding for high-cardinality categorical features and quantile transformation, the exact implementation details were not replicated. Instead, GRANDE's internal preprocessing was used, which may differ from the authors' original code.\n",
    "- All experiments used a fixed random seed (42) for reproducibility.\n",
    "- Experiments ran on Windows CPU.\n",
    "- \n",
    "**Results Comparison with Original Paper**\n",
    "  \n",
    "WDBC Dataset\n",
    "\\begin{array}{lccc}\n",
    "\\textbf{Model} & \\textbf{Paper F1-Score} & \\textbf{Reproduction F1-Score}\\\\\n",
    "\\hline\n",
    "\\text{GRANDE} & $0.975 \\pm 0.010$ & $0.964 \\pm 0.009$ \\\\\n",
    "\\text{XGBoost} & $0.953 \\pm 0.030$ & $0.960 \\pm 0.021$ \\\\\n",
    "\\text{CatBoost} & $0.963 \\pm 0.023$ & $0.961 \\pm 0.020$ \\\\\n",
    "\\end{array}\n",
    "Assessment: All methods achieve comparable performance with reported values. The paper showed GRANDE with clear superiority, while reproduction shows near-parity among all methods.\n",
    "\n",
    "Churn Dataset\n",
    "\n",
    "\\begin{array}{lccc}\n",
    "\\textbf{Model} & \\textbf{Paper F1-Score} & \\textbf{Reproduction F1-Score}\\\\\n",
    "\\hline\n",
    "\\text{GRANDE} & $0.914 \\pm 0.017$ & $0.906 \\pm 0.004$ \\\\\n",
    "\\text{XGBoost} & $0.900 \\pm 0.017$ & $0.910 \\pm 0.010$ \\\\\n",
    "\\text{CatBoost} & $0.869 \\pm 0.021$ & $0.910 \\pm 0.010$ \\\\\n",
    "\\end{array}\n",
    "Assessment: CatBoost substantially outperforms the paper's reported results, reversing the ranking from GRANDE-first to CatBoost-first. The reason could be different fold variability or potential methodological differences.\n",
    "\n",
    "PhishingWebsites Dataset\n",
    "\n",
    "\\begin{array}{lccc}\n",
    "\\textbf{Model} & \\textbf{Paper F1-Score} & \\textbf{Reproduction F1-Score} \\\\\n",
    "\\hline\n",
    "\\text{GRANDE} & $0.969 \\pm 0.006$ & $0.968 \\pm 0.003$ \\\\\n",
    "\\text{XGBoost} & $0.968 \\pm 0.006$ & $0.968 \\pm 0.002$ \\\\\n",
    "\\text{CatBoost} & $0.965 \\pm 0.003$ & $0.965 \\pm 0.002$ \\\\\n",
    "\\end{array}\n",
    "Assessment: All methods match the paper's results with very small diferences.\n",
    "\n",
    "While PhishingWebsites shows the expected competitive performance, WDBC shows reduced GRANDE advantage, and Churn shows unexpected CatBoost superiority. This suggests performance rankings may be sensitive to implementation details. Different results between the reproduction and the paper may indicate differences in data splitting, preprocessing, or inherent properties of library implementations. Two of three datasets show non-trivial deviations, suggesting that exact numerical reproduction requires matching the complete software stack and implementation data.\n",
    "\n",
    "The reproduction uses an explicit 80/20 train-validation split within each fold for GRANDE's early stopping. The paper's description is ambiguous about whether a separate validation set was used or whether early stopping relied on other criteria. Different validation strategies affect the effective training data size and model convergence."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7d92f25-9a6c-42e0-a458-e98d58378e0a",
   "metadata": {},
   "source": [
    "### References\n",
    "\n",
    "https://arxiv.org/pdf/2309.17130\n",
    "\n",
    "https://github.com/s-marton/GRANDE\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5f82ae-ab8e-4c6d-b8f0-69d222dab826",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:grande-project]",
   "language": "python",
   "name": "conda-env-grande-project-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
